{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import json\n",
    "import jieba\n",
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path,tokens_only=False):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "\n",
    "        #words=[]\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = json.loads(line)\n",
    "            question = line['title']\n",
    "            q_list = jieba.cut(question)\n",
    "           # words.append(' '.join(q_list).split())\n",
    "            words = ' '.join(q_list).split()\n",
    "            for i,line in enumerate(words):\n",
    "                if tokens_only:\n",
    "                    yield gensim.utils.simple_preprocess(question)\n",
    "                else:\n",
    "                 yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line), [i])\n",
    "\n",
    "\n",
    "\n",
    "file_path = 'E:/litao/Chatbots/data/baike_qa/baike_qa_train.json'\n",
    "train_corpus = read_data(file_path)\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "model.build_vocab(train_corpus)\n",
    "model.save('baike_qa2vec.model')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2vec(sent):\n",
    "    model = Doc2Vec.load('baike_qa2vec.model')\n",
    "    sent_list = jieba.cut(sent)\n",
    "    words = ' '.join(sent_list).split()\n",
    "    sent2vec = model.infer_vector(words) \n",
    "    return sent2vec\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def tem_vec(file_path):\n",
    "    d2v = []\n",
    "    an_dict = {}\n",
    "    f = open(file_path,'r', encoding='utf-8')\n",
    "    for i,line in enumerate(f.readlines()[:1000]):\n",
    "        line = json.loads(line)\n",
    "        question = line['title']\n",
    "        answer = line['answer']\n",
    "        v =  doc2vec(question)\n",
    "       # print(v)\n",
    "        \n",
    "        #print (question,answer)\n",
    "        d2v.append(v)\n",
    "        an_dict[i] = (question,answer)\n",
    "    return d2v,an_dict\n",
    "file_path = 'E:/litao/Chatbots/data/baike_qa/baike_qa_train.json'    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.745 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "d2v,an_dict = tem_vec(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import norm\n",
    "def vector_similarity(v,d2v,an_dict):\n",
    "    sims =  []\n",
    "    sims_dict ={}\n",
    "    for i,v2 in enumerate(d2v):\n",
    "                sim = np.dot(v, v2) / (norm(v) * norm(v2))\n",
    "                sims.append(sim)\n",
    "                sims_dict[sim] = i\n",
    "    sims.sort(reverse=True)\n",
    "    top_n = 3\n",
    "    for i in range(top_n):\n",
    "        print (sims[i])\n",
    "        print(an_dict[sims_dict[sims[i]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "0.9999999348428951\n",
      "('松本面板可以配什么品牌的超五类模块?? ', 'AMP的试试吧，还有普天的。')\n",
      "0.4921991317660698\n",
      "('《项链》的作者是谁 ', '这是莫泊桑的短篇小说. ')\n",
      "0.41631020173882854\n",
      "('我家墙面是白色地面是黄色的窗帘买什么颜色的好 ', '橙色')\n",
      "---------\n",
      "0.44393269306124394\n",
      "('成人本科挂名我现在在的学校的信息管理专业是4年脱产成人本科,挂靠 ', '可能是挂靠学校没有本科资格,因此与南农合作办学,所以你应该算是南农成教的学生.你和南农成教的学生可能不在一起上课,但你仍可以拿南农的成人本科证\\r\\n成人学校也是按分上的,和高考一样\\r\\n在北京,一些普通高校的成教学院的分就比独立设置的成人高校分数明显高很多.')\n",
      "0.4425346811938248\n",
      "('农村家庭用的太阳能热水器哪个牌子好？因为想在农村做太阳能热水器生 ', '现在市面上的品牌很多,大家还是选择皇明的较多.如果经济条件允许还是选择皇明,售后服务会好一些.不知道现在的太阳能热水器是否带泵,因压力不够淋浴时水不足.安装时能配套就更好了.保温管是需要关注的,保证在北方室外温度较低时能正常使用.曾遇到几次早晨没有热水可用的麻烦事. \\r\\n你可以打他们的服务电话0371-65653835 \\r\\n')\n",
      "0.39105994107243985\n",
      "('如何在比赛中更换阵型？？？ ', '改变阵形在球队管理里面。进入球队管理以后，看左下角。会有一个阵形的小图框。你只需要点上面的“<”或者点“>”就可以改变阵形了。建议你改变阵形以后，设置好替补阵容。然后点下保存。那样你以后都会是那种阵形了\\r\\n在比赛中暂停，可进行换人、换阵型、设置盯人、罚球，多人模式比赛时需要己方控球才能暂停')\n",
      "---------\n",
      "0.45698341715420004\n",
      "('咳嗽咳嗽还是咳嗽，谁有妙招能治幼儿咳嗽 ', '把一雪梨核去掉，放入四块冰糖，四颗川贝的量（有卖粉的），合上梨。放在铁碗里干蒸，锅里放水。每天都吃一只梨。呵呵，三四天后明显好转 祝你好运')\n",
      "0.3857136195735292\n",
      "('我想办一张能透支的银行卡,哪个银行的好,有什么要求,还有哪个银行? ', '办张贷记卡吧,消费透支在一定时期内不用付费,\\r\\n工行的如果你没有什么固定单位,定期存单质押也可以办卡,\\r\\n他还可以选择消费时密码用或不用,也可选择多少金额才开始用,很好的')\n",
      "0.38496022805319513\n",
      "('拜仁4', '这也叫拼?哈哈!')\n",
      "---------\n",
      "Word2vec相似度运行时间： 1.1153333187103271\n"
     ]
    }
   ],
   "source": [
    "from time import *\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "begin_time = time()  \n",
    "userinput1 = '松本面板可以配什么品牌的超五类模块??'\n",
    "\n",
    "userinput3 = '万能的微博，深圳有维修饰品的地方么？'\n",
    "\n",
    "v1 = doc2vec(userinput1)\n",
    "v2 = doc2vec(userinput2)\n",
    "v3 = doc2vec(userinput3)\n",
    "print('---------') \n",
    "vector_similarity(v1,d2v,an_dict)\n",
    "print('---------') \n",
    "vector_similarity(v2,d2v,an_dict)\n",
    "print('---------') \n",
    "vector_similarity(v3,d2v,an_dict)\n",
    "print('---------') \n",
    "end_time=time()\n",
    "run_time = (end_time-begin_time)/3\n",
    "print ('Word2vec相似度运行时间：',run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000294002356\n"
     ]
    }
   ],
   "source": [
    "userinput2 = '万能的微博，深圳有维修饰品的地方么？断了'\n",
    "userinput1 = '万能的微博，深圳有维修饰品的地方么？断了'\n",
    "v2 = doc2vec(userinput2)\n",
    "v1 = doc2vec(userinput1)\n",
    "print( np.dot(v1, v2) / (norm(v1) * norm(v2)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
